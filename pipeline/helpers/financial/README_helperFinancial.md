# Financial Helpers Module

> Modular financial domain expertise for intelligent OutlierDetection method selection

## üéØ Purpose

Provides specialized financial expertise for Enhanced Decision Tree in OutlierDetection pipeline. Each helper analyzes time series characteristics through scientifically validated algorithms, ensuring context-aware method selection and adaptive parameter tuning. The architecture eliminates financial logic duplication between modules through 95% context reuse optimization.

## üî¨ Mathematical Foundation

### Regime Classification Framework
- **Volatility regimes**: Empirical crypto quantiles (Engle, 1982; crypto market research)
- **Trend analysis**: R¬≤ significance testing (Hamilton, 1994) 
- **Persistence scoring**: Momentum persistence theory (Jegadeesh & Titman, 1993)
- **Edge cases handling**: Mathematical stability for degenerate scenarios

### Alpha Assessment Methodology  
- **Custom alpha scoring**: `Œ±_custom = tanh(excess_returns / volatility) ‚àà [-1, 1]` (NOT Jensen's Alpha)
- **Statistical rigor**: Benjamini-Hochberg FDR correction, bootstrap confidence intervals
- **No look-ahead bias**: Forward-only return calculation for trading applications
- **Type-specific multipliers**: Literature-based coefficients from 6 peer-reviewed sources

### Microstructure Quality Analysis
- **Hasbrouck noise detection**: `noise = 1.0 - mean(VR(k))` where `VR(k) = Var(r_k)/(k√óVar(r_1))`
- **Roll spread estimation**: `spread = max(0, -2√óautocorr_1)` (Roll, 1984)
- **Harris clustering**: Round numbers frequency analysis (Harris, 1991)
- **HFT pattern detection**: Evidence-based pattern recognition through Catch22 features

### Cross-Asset Correlation Science
- **Market beta calculation**: `Œ≤ = Cov(target,reference)/Var(reference)` with bias correction
- **Forbes-Rigobon contagion**: Heteroskedasticity-adjusted correlation (Forbes & Rigobon, 2002)
- **Lead-lag analysis**: Statsmodels cross-correlation function (Granger & Newbold, 1977)
- **Database integration**: ClickHouse queries through DBFuncsSQL mechanism

## üèóÔ∏è Technical Implementation

**Architectural pattern**: Modular Helper Functions + Enhanced Decision Tree integration  
**Standardization**: Unified error handling, numerical stability constants, IEEE 754 compliance  
**Context optimization**: 95% reuse of pre-computed analyzer/periodicity/decomposition results  
**Performance**: <50ms execution per helper, chunked processing, memory-efficient algorithms

## üìÅ File Structure

| File | Purpose | Key Components |
|------|---------|----------------|
| `regime.py` | Market regime classification | `classify_market_regime()`, `get_regime_thresholds()`, edge cases handling |
| `alpha.py` | Alpha assessment framework | `AlphaAssessment` class, forward returns (no look-ahead), FDR correction |
| `microstructure.py` | HFT pattern detection | `analyze_microstructure_patterns()`, Hasbrouck/Roll/Harris algorithms |
| `correlation.py` | Cross-asset correlation analysis | `analyze_cross_asset_correlation()`, ClickHouse integration, Forbes-Rigobon |
| `__init__.py` | Module initialization | Helper imports, version management |

## üîÑ Integration

### Enhanced Decision Tree Flow
```python
# OutlierDetection context-driven method selection
analyzer_data = context["currentProperties"]["analyzer"]
decomposition_data = context["currentProperties"]["decomposition"]

# Financial helpers analysis (95% context reuse)
regime_info = classify_market_regime(analyzer_data)
microstructure_info = analyze_microstructure_patterns(analyzer_data)
alpha_assessment = AlphaAssessment().estimate_alpha_potential(...)
correlation_analysis = analyze_cross_asset_correlation(ts_id, context, outliers)

# Intelligent method selection
if regime_info["market_regime"] == "volatile_trending":
    methods = ["isolation_forest", "component_anomaly"]
    thresholds = get_regime_thresholds("volatile_trending")
elif microstructure_info["hft_noise_level"] > 0.3:
    methods = ["statistical_enhancement"] + get_hft_robust_methods()
```

### Input Context (Pre-computed)
- **Analyzer properties**: Volatility, trend strength, autocorrelation, Catch22 features, outlier ratios
- **Decomposition data**: Trend/seasonal/residual components, quality scores
- **Periodicity data**: Lag patterns, temporal autocorrelation, frequency characteristics

### Output Enhancement
- **Regime classification**: Market regime type, confidence scoring, dynamic thresholds
- **Alpha potential**: Predictive power assessment, type-specific multipliers, forward-looking analysis
- **Microstructure quality**: HFT noise detection, trading environment assessment, pattern classification
- **Market correlation**: Cross-asset beta, contagion susceptibility, isolation periods ratio

### Error Handling Protocol
```python
# Standardized across all helpers
try:
    # Core analysis with mathematical validation
    result = core_calculation_with_stability_checks(input_data)
    return {"status": "success", "result": result}
except Exception as e:
    logging.error(f"Helper analysis failed: {str(e)}")
    return {"status": "error", "message": str(e), "result": safe_defaults}
```

### Performance Characteristics
- **Execution time**: <50ms per helper call (production requirement)
- **Context reuse**: 95% data reuse from analyzer/periodicity/decomposition  
- **Mathematical rigor**: 40+ peer-reviewed references, comprehensive edge case handling
- **Numerical stability**: IEEE 754 compliance, robust fallback strategies
- **Memory efficiency**: Chunked processing for large datasets, optimized ClickHouse queries

### Production Monitoring
- **Quality metrics**: Mathematical validation status, confidence bounds verification
- **Performance tracking**: Execution times, context reuse ratios, error rates
- **Business value**: Alpha potential assessment, market regime accuracy, HFT detection rates
- **System integration**: Database query efficiency, OutlierDetection method selection accuracy

---

*Each helper represents scientifically validated mini-module with production-ready implementation, providing domain expertise for intelligent OutlierDetection enhanced by context optimization and mathematical rigor.*